{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reddit Vaccine Myth Sentiment Analysis\n\nAccording to the description of this dataset, r/VaccineMyths is a subreddit where myths related to various vaccines are discussed.\n\nIt contains both posts and comments.\n\nOur task is to perform sentiment analysis and then topic modeling on this dataset.\nThe topic modeling will be particularly helpful for the medical study of this dataset, because it will let us better understand what are the factors that are related to the originating of particular types of myths surrouding the vaccines.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndataset_path = os.path.join(dirname, filenames[0])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-01T17:26:30.727199Z","iopub.execute_input":"2021-10-01T17:26:30.728073Z","iopub.status.idle":"2021-10-01T17:26:31.662588Z","shell.execute_reply.started":"2021-10-01T17:26:30.728011Z","shell.execute_reply":"2021-10-01T17:26:31.661490Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Class for decorated printing\n# Source: https://stackoverflow.com/a/17303428\nclass color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:31.664086Z","iopub.execute_input":"2021-10-01T17:26:31.665000Z","iopub.status.idle":"2021-10-01T17:26:31.669611Z","shell.execute_reply.started":"2021-10-01T17:26:31.664967Z","shell.execute_reply":"2021-10-01T17:26:31.668913Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Read data\ndf = pd.read_csv(dataset_path)\n# Print top 5 rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:31.670588Z","iopub.execute_input":"2021-10-01T17:26:31.671379Z","iopub.status.idle":"2021-10-01T17:26:31.741441Z","shell.execute_reply.started":"2021-10-01T17:26:31.671351Z","shell.execute_reply":"2021-10-01T17:26:31.740630Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory Data Analysis\n\nI have written some reusable utility functions for the EDA","metadata":{}},{"cell_type":"code","source":"# Shape of dataset\nprint(f'Shape of dataset: {df.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:31.743087Z","iopub.execute_input":"2021-10-01T17:26:31.743894Z","iopub.status.idle":"2021-10-01T17:26:31.747867Z","shell.execute_reply.started":"2021-10-01T17:26:31.743862Z","shell.execute_reply":"2021-10-01T17:26:31.747149Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def basic_information(df):\n    print(color.PURPLE + color.BOLD + 'Description: \\n' + color.END)\n    display(df.describe())\n    print(color.PURPLE + color.BOLD + '\\nInformation: \\n' + color.END)\n    display(df.info())\n    print(color.PURPLE + color.BOLD + '\\nNaN Values: \\n' + color.END)\n    display(pd.isna(df).sum())","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:31.749310Z","iopub.execute_input":"2021-10-01T17:26:31.749551Z","iopub.status.idle":"2021-10-01T17:26:31.761712Z","shell.execute_reply.started":"2021-10-01T17:26:31.749524Z","shell.execute_reply":"2021-10-01T17:26:31.760999Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def feature_type(df):\n    '''\n    This function finds which features in given dataframe \n    are of categorical type and which are numerical\n    \n    Input - df:Dataframe\n    Output - categorical_features:list, numerical_features:list \n    '''\n    categorical_features = []\n    numerical_features = []\n    \n    for column in df.columns:\n        if df[column].dtype == object:\n            categorical_features.append(column)\n        else:\n            numerical_features.append(column)\n            \n    return categorical_features, numerical_features","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:31.762868Z","iopub.execute_input":"2021-10-01T17:26:31.763514Z","iopub.status.idle":"2021-10-01T17:26:31.775108Z","shell.execute_reply.started":"2021-10-01T17:26:31.763482Z","shell.execute_reply":"2021-10-01T17:26:31.774145Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"basic_information(df)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T18:04:49.309452Z","iopub.execute_input":"2021-10-01T18:04:49.309782Z","iopub.status.idle":"2021-10-01T18:04:49.348351Z","shell.execute_reply.started":"2021-10-01T18:04:49.309752Z","shell.execute_reply":"2021-10-01T18:04:49.347178Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"categorical_features, numerical_features = feature_type(df)\nprint(color.PURPLE + color.BOLD + 'Categorical Features: ' + color.END + f'{categorical_features}')\nprint(color.PURPLE + color.BOLD + 'Categorical Features: ' + color.END + f'{categorical_features}')","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:32.065452Z","iopub.execute_input":"2021-10-01T17:26:32.066207Z","iopub.status.idle":"2021-10-01T17:26:32.071713Z","shell.execute_reply.started":"2021-10-01T17:26:32.066169Z","shell.execute_reply":"2021-10-01T17:26:32.071136Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"From here, we can see the basic statistical details of the dataset\nWe can observe that the columns **url** and **body** contain null data.\nAlso the dataset contains categorical as well as numerical features.","metadata":{}},{"cell_type":"markdown","source":"## Visualizing patterns in the occurrence of missing values\n\nHere we would like to see if there is some pattern in the occurrence of the missing values of a column or not. For eg. Are missing values sparsely localted all over the domain, or just located together somewhere specifically as a chunk.\n\nWith a heatmap, we would also be able to observe if there is any positive or negative co-occurrence relation between missing values of different columns.","metadata":{}},{"cell_type":"code","source":"# Visualizing patterns in the occurrence of missing values\nplt.figure(figsize=(7,7))\nsns.heatmap(df.isna(), cbar=False)\nplt.title(\"Heatmap of missing data pattern\", fontsize=25)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:33.497691Z","iopub.execute_input":"2021-10-01T17:26:33.498153Z","iopub.status.idle":"2021-10-01T17:26:33.963498Z","shell.execute_reply.started":"2021-10-01T17:26:33.498108Z","shell.execute_reply":"2021-10-01T17:26:33.962669Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"We can observe that for url column, there is a bulk absence of values for a part of the domain. Also, there is somewhat a negative correlation between the missing values of **url** and those of **body**, meaning missing values are present for the part fo domain in **body**, where they are present for **url** and vice-versa.","metadata":{}},{"cell_type":"code","source":"# Creating month and year indices with the timestamp data of the dataset\ndf['year'] = pd.DatetimeIndex(df['timestamp']).year\ndf['month'] = pd.DatetimeIndex(df['timestamp']).month","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:26:34.269662Z","iopub.execute_input":"2021-10-01T17:26:34.270066Z","iopub.status.idle":"2021-10-01T17:26:34.279553Z","shell.execute_reply.started":"2021-10-01T17:26:34.270033Z","shell.execute_reply":"2021-10-01T17:26:34.278916Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.heatmap(df.corr(), annot=True)\nplt.title(\"Heatmap of co-occurrence matrix\", fontsize=25)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:27:02.801666Z","iopub.execute_input":"2021-10-01T17:27:02.802506Z","iopub.status.idle":"2021-10-01T17:27:03.161557Z","shell.execute_reply.started":"2021-10-01T17:27:02.802469Z","shell.execute_reply":"2021-10-01T17:27:03.160906Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"We can see there is a high correlation between **year** and **created**, and **comms_num** and **score**, so one column can be dropped in each pair","metadata":{}},{"cell_type":"code","source":"df.drop(labels=['created', 'comms_num', 'url', 'id', 'timestamp'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T18:05:14.289577Z","iopub.execute_input":"2021-10-01T18:05:14.290623Z","iopub.status.idle":"2021-10-01T18:05:14.302252Z","shell.execute_reply.started":"2021-10-01T18:05:14.290575Z","shell.execute_reply":"2021-10-01T18:05:14.301356Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}